# Bridging the Gap Between AI Planning and Reinforcement Learning (PRL @ IJCAI 2023) â€“ [Workshop at IJCAI 2023](https://ijcai-23.org)

IJCAI'23 Workshop \
Macao, S.A.R \
August 20, 2023 (Full Day) \
Room: Almaty 6003

## Aim and Scope of the Workshop

While AI Planning and Reinforcement Learning communities focus on similar
sequential decision-making problems, these communities remain somewhat unaware
of each other on specific problems, techniques, methodologies, and evaluations.

This workshop aims to encourage discussion and collaboration between researchers in the fields of AI planning and reinforcement learning. 
We aim to bridge the gap between the two communities, facilitate the discussion of differences and similarities in existing techniques, and encourage collaboration across the fields. 
We solicit interest from AI researchers that work in the
intersection of planning and reinforcement learning, in particular, those that focus on intelligent decision-making. This is the sixth edition of the [PRL workshop series](https://prl-theworkshop.github.io/) that started at [ICAPS 2020](https://icaps20subpages.icaps-conference.org/workshops/prl/).

## Topics of Interest

We invite submissions at the intersection of AI Planning and Reinforcement Learning. The topics of interest include, but are not limited to, the following

* Reinforcement learning (model-based, Bayesian, deep, hierarchical, etc.)
* Safe RL
* Monte Carlo planning
* Model representation and learning for planning
* Planning using approximated/uncertain (learned) models
* Learning search heuristics for planner guidance
* Theoretical aspects of planning and reinforcement learning
* Action policy analysis or certification
* Reinforcement Learning and planning competition(s)
* Multi-agent planning and learning
* Applications of both reinforcement learning and planning 


## Important Dates

* Paper submission deadline: ~~May, 4th, AOE~~ ~~May 11th, AOE~~ **May 18th, AOE**
* Paper acceptance notification: ~~June 5th, AOE~~ **June 9th, AOE**

## Submission Details


We solicit workshop paper submissions relevant to the above call of the following types:

 * Long papers -- up to 8 pages + unlimited references / appendices
 * Short papers -- up to 4 pages + unlimited references / appendices
 * Extended abstracts -- up to 2 pages + unlimited references/appendices 
 
Please format submissions in AAAI style (see instructions in the [Author Kit](https://www.aaai.org/Publications/Templates/AuthorKit23.zip)). Authors submitting papers rejected from other conferences, please ensure you do your utmost to address the comments given by the reviewers. Please do not submit papers that are already accepted for the main IJCAI conference to the workshop.

**Note for NeurIPS resubmissions**: For authors resubmitting their NeurIPS submissions to PRL, please ensure they are *anonymized*. For these resubmissions, there is no need to reformat to AAAI. Authors can keep the *NeurIPS formatting* as we will allow the papers in NeurIPS format to be nine pages.

Some accepted long papers will be invited for contributed talks. All accepted papers (long as well as short) and extended abstracts will be given a slot in the poster
presentation session.  Extended abstracts are intended as brief summaries of already published papers,  preliminary work, position papers, or challenges that
might help bridge the gap.

As the main purpose of this workshop is to solicit discussion, the authors are
invited to use the appendix of their submissions for that purpose.


Paper submissions should be made through [OpenReview](https://openreview.net/group?id=PRL/2023/IJCAI).


## Schedule



| Start Time (Macao local time) | Title |
|:------------:|:-----------|
|     9:00     | Opening Remarks          |
|         |  **Session 1**      |
|  9:10 | Theoretically Guaranteed Policy Improvement Distilled from Model-Based Planning |
|  9:30 |Learning to Plan with Tree Search via Deep RL |
| 9:50 | Learning Parameterized Policies for Planning Annotated RL |
| 10:10 | Generalized Planning in PDDL Domains with Pretrained Large Language Models |
|    10:30     | ---Coffee break--- |
|    11:00     | [*Invited Talk: Siddharth Srivastava*](#siddharth-srivastava) <br> **Learning Abstractions for Generalizable Planning, Learning, and Reinforcement Learning.** |
|    | **Session 2**   |
| 11:50 | Learning to Create Abstraction Hierarchies for Motion Planning under Uncertainty |
| 12:10 | Learn to Follow: Lifelong Multi-agent Pathfinding with Decentralized Replanning |
|    12:30     | ---Lunch---    |
|    14:00  | [*Invited Talk: Akhil Bagaria*](#akhil-bagaria) <br> **Skill Discovery for Exploration and Planning** <br> <!--Bio: Akhil Bagaria is a PhD candidate at Brown University working on RL with George Konidaris. Prior to that, he worked on the multitouch team at Apple where he developed gesture recognition algorithms that are shipping on Macbooks and iPads. He did his undergrad from Harvey Mudd College in Southern California, where his research included tracking sharks with autonomous underwater robots. --> |
|        | **Session 3**    | 
| 14:50 | TBA |
| 15:10 | Object-Centric Learning of Neural Policies for Zero-shot Transfer over Domains with Varying Quantities of Interest |
|    15:30     | ---Coffee break--- |
|    16:00     | Concluding Remarks |
|    16:10   | **Poster Session** |
|    17:30   | -- END -- |

##  Invited Talks


### Siddharth Srivastava

<div style="text-align: center;">

<img style="border-radius: 50%;overflow: hidden;background-color:#373737;height: 200px;object-fit: cover;" width="200px"  src="http://siddharthsrivastava.net/srivastava.jpg">
</div> 

<!-- <div style="text-align: center;"> -->

**Learning Abstractions for Generalizable Planning, Learning, and Reinforcement Learning**


Can we build autonomous agents that learn generalizable knowledge and use it to reliably accomplish previously unseen tasks? In this talk, I will present our recent advances in neuro-symbolic learning for a range of sequential decision-making problems that feature long horizons and sparse rewards. Using results from our recent work, I will discuss how learning and using abstractions not only reduces the need for human input, but also helps ensure correctness and extends generalizability of learned knowledge to problems that were not seen during training. Throughout the talk, I will illustrate research advances with results in a variety of sequential decision-making settings including long-horizon planning under uncertainty, reinforcement learning, and robot planning.

> *[Siddharth Srivastava](http://siddharthsrivastava.net) is an Associate Professor of Computer Science in the School of Computing and Augmented Intelligence at Arizona State University.  He received his PhD in Computer Science at the University of Massachusetts, Amherst, and did his postdoctoral research at UC Berkeley. His research focuses on safe and reliable taskable AI systems, AI assessment, and AI safety. He is a recipient of the NSF CAREER award, a Best Paper award at the International Conference on Automated Planning and Scheduling (ICAPS), an Outstanding Dissertation award at UMass Amherst, and a Best Final Year Thesis Award at IIT Kanpur. He served as conference Co-Chair for ICAPS 2019 and currently serves as an Associate Editor for the Journal of AI Research.*

<!-- </div>  -->


### Akhil Bagaria

<div style="text-align: center;">
<img  style="border-radius: 50%;overflow: hidden;background-color:#373737;height: 200px;object-fit: cover;" width="200px"  src="https://abagaria.github.io/img/abagaria2.JPG">
</div> 


**Skill Discovery for Exploration and Planning.** 

<!-- Abstract: TBA -->

> *[Akhil Bagaria](https://abagaria.github.io) is a PhD candidate at Brown University working on RL with George Konidaris. Prior to that, he worked on the multitouch team at Apple where he developed gesture recognition algorithms that are shipping on Macbooks and iPads. He did his undergrad from Harvey Mudd College in Southern California, where his research included tracking sharks with autonomous underwater robots.*


## List of Accepted Papers

- [poster only] A Learnable Similarity Metric for Transfer Learning with Dynamics Mismatch
- [poster only] Contextual Pre-Planning on Reward Machine Abstractions for Enhanced Transfer in Deep Reinforcement Learning
- [oral+poster] Exploiting Long-Range Influences in Learning Generalized Neural Policies for RDDL Relational MDPs
- [oral+poster] Generalized Planning in PDDL Domains with Pretrained Large Language Models
- [oral+poster] Learn to Follow: Lifelong Multi-agent Pathfinding with Decentralized Replanning
- [poster only] Learning and Leveraging Verifiers to Improve Planning Capabilities of Pre-trained Language Models
- [poster only] Learning Neuro-Symbolic World Models with Logical Neural Networks
- [oral+poster] Learning Parameterized Policies for Planning Annotated RL
- [poster only] Learning State Reachability as a Graph in Translation Invariant Goal-based Reinforcement Learning Tasks
- [oral+poster] Learning to Create Abstraction Hierarchies for Motion Planning under Uncertainty
- [poster only] Learning to Plan with Tree Search via Deep RL
- [oral+poster] Object-Centric Learning of Neural Policies for Zero-shot Transfer over Domains with Varying Quantities of Interest
- [poster only] Optimistic Exploration in Reinforcement Learning Using Symbolic Model Estimates
- [poster] Task Scoping: Generating Task-Specific Simplifications of Open-Scope Planning Problems
- [oral+poster] Theoretically Guaranteed Policy Improvement Distilled from Model-Based Planning
- [poster only] Towards More Likely Models for AI Planning
- [poster only] Using Reverse Reinforcement Learning for Assembly Tasks

<!-- ### Workshop Proceedings (optional)

TODO

### Policy on Previously Published Materials (optional) 

TODO -->

<!-- ## Workshop Committee

TODO -->

### Organizing Committee

* Cameron Allen, Brown University, RI, USA 
* Timo P. Gros, Saarland University, Germany
* Michael Katz, IBM T.J. Watson Research Center, NY, USA
* Harsha Kokel, University of Texas at Dallas, TX, USA
* Hector Palacios, ServiceNow Research, Montreal, Canada
* Sarath Sreedharan, Colorado State University, CO, USA



Please send your inquiries to prl.theworkshop@gmail.com


<!-- ### Program Committee

TODO -->

<!-- ## Workshop Schedule

TBD -->


