# Bridging the Gap Between AI Planning and Reinforcement Learning (PRL) – [Workshop at ICAPS 2021 (August 5-6)](https://icaps21.icaps-conference.org/workshops/PRL/)

### This site presents the most up-to-date information about the workshop. Please, visit [ICAPS 2021](https://icaps21.icaps-conference.org/) for more general information.

While AI Planning and Reinforcement Learning communities focus on similar sequential decision-making problems, these communities remain somewhat unaware of each other on specific problems, techniques, methodologies, and evaluation.

This workshop aims to encourage discussion and collaboration between the researchers in the fields of AI planning and reinforcement learning. We aim to bridge the gap between the two communities, facilitate the discussion of differences and similarities in existing techniques, and encourage collaboration across the fields. We solicit interest from AI researchers that work in the intersection of planning and reinforcement learning, in particular, those that focus on intelligent decision making. As such, the joint workshop program is an excellent opportunity to gather a large and diverse group of interested researchers.

## Topics

The workshop solicits work at the intersection of the fields of reinforcement learning and planning. We also solicit work solely in one area that can influence advances in the other so long as the connections are clearly articulated in the submission.

Submissions are invited for topics on, but not limited to:

- Reinforcement learning (model-based, Bayesian, deep, etc.)
- Model representation and learning for planning
- Planning using approximated/uncertain (learned) models
- Monte Carlo planning
- Learning search heuristics for planner guidance
- Theoretical aspects of planning and reinforcement learning
- Reinforcement Learning and planning competition(s)
- Multi-agent planning and learning
- Applications of both reinforcement learning and planning

## Invited Speakers

- [Aviv Tamar](https://avivt.github.io/avivt/) – "Learning to Plan and Planning to Learn"
- [Danijar Hafner](https://danijar.com)
- [Emma Brunskill](https://cs.stanford.edu/people/ebrun/)
- [André Barreto](https://www.lncc.br/~amsb/) – "Value-Based Representation and Model Learning"
- [Elias Bareinboim](https://causalai.net)

## Program (subject to minor changes)

The event will be fully virtual, consisting of:

* Invited talks. 30m + 10m for Q&A.
* Oral presentations for some papers. 8m + 2m for Q&A.
* One poster session. 60m.
* Discussion sessions. 20m.

The program spans 10 hours split into two consecutive days

### August 5 (10:00 to 15:00 US East time)

|10:00| Invited Talk     |
|10:40|	Contributed talk |


| First Header  | Second Header |
| ------------- | ------------- |
| Content Cell  | Content Cell  |
| Content Cell  | Content Cell  |

10:50	Contributed talk

11:00	Break

11:15	Invited Talk
11:55	Discussion Session
12:15	Posters
13:15	Break
13:30	Invited Talk: Peter Stone
14:10	Contributed talk
14:20	Contributed talk
14:30	Contributed talk
14:40	Discussion Session

### August 6 (10:00 to 15:00 US East time)
10:00	Invited Talk
10:40	Contributed talk
10:50	Contributed talk
11:00	Contributed talk
11:10 Discussion Session
11:30	Break
11:45 Invited Talk
12:25	Contributed talk
12:35	Contributed talk
12:45 Contributed talk
12:55	Discussion Session and Closing remarks

## Accepted papers

* Open-Loop Online Planning for F1 Race Strategy Identification ([PDF](prl2021/papers/PRL2021_paper_1.pdf))
* SOLO: Search Online, Learn Offline for Combinatorial Optimization Problems ([PDF](prl2021/papers/PRL2021_paper_4.pdf))
* RePReL : Integrating Relational Planning and Reinforcement Learning for Effective Abstraction ([PDF](prl2021/papers/PRL2021_paper_5.pdf))
* Neural Network Action Policy Verification via Predicate Abstraction ([PDF](prl2021/papers/PRL2021_paper_7.pdf))
* A Reinforcement Learning Environment For Job-Shop Scheduling ([PDF](prl2021/papers/PRL2021_paper_9.pdf))
* Learning Search Guidance from Failures with Eliminable Edge Sets ([PDF](prl2021/papers/PRL2021_paper_10.pdf))
* First-Order Function Approximation for Transfer Learning in Relational MDPs ([PDF](prl2021/papers/PRL2021_paper_11.pdf))
* AlwaysSafe: Reinforcement Learning without Safety Constraint Violations during Training (Extended Abstract) ([PDF](prl2021/papers/PRL2021_paper_13.pdf))
* Can Reinforcement Learning solve the Human Allocation Problem? ([PDF](prl2021/papers/PRL2021_paper_15.pdf))
* Debugging a Policy: A Framework for Automatic Action Policy Testing ([PDF](prl2021/papers/PRL2021_paper_16.pdf))
* Planning with Rolling Horizon Evolution using learned State Space Models ([PDF](prl2021/papers/PRL2021_paper_17.pdf))
* Neural Network Heuristic Functions for Classical Planning: Reinforcement Learning and Comparison to Other Methods ([PDF](prl2021/papers/PRL2021_paper_20.pdf))
* Discount Factor Estimation in a Model-Based Inverse Reinforcement Learning Framework ([PDF](prl2021/papers/PRL2021_paper_21.pdf))
* Obtaining Approximately Admissible Heuristic Functions through Deep Reinforcement Learning and A* Search ([PDF](prl2021/papers/PRL2021_paper_23.pdf))
* dcss ai wrapper: An API for Dungeon Crawl Stone Soup providing both Vector and Symbolic State Representations ([PDF](prl2021/papers/PRL2021_paper_24.pdf))
* Reinforcement Learning for Classical Planning: Viewing Heuristics as Dense Reward Generators ([PDF](prl2021/papers/PRL2021_paper_26.pdf))
* A Generic Dialog Agent for Information Retrieval Based on Automated Planning Within a Reinforcement Learning Platform ([PDF](prl2021/papers/PRL2021_paper_28.pdf))
* Scalable Risk-Sensitive Planning by Gradient Descent ([PDF](prl2021/papers/PRL2021_paper_30.pdf))
* Extending Graph Neural Networks for Generalized Stochastic Planning ([PDF](prl2021/papers/PRL2021_paper_31.pdf))
* Bounded-Suboptimal Search with Learned Heuristics ([PDF](prl2021/papers/PRL2021_paper_33.pdf))
* Guiding Robot Exploration in Reinforcement Learning via Automated Planning: an Abstract ([PDF](prl2021/papers/PRL2021_paper_35.pdf))
* AI Planning Annotation in Reinforcement Learning: Options and Beyond ([PDF](prl2021/papers/PRL2021_paper_36.pdf))
* Efficient PAC Reinforcement Learning in Regular Decision Processes ([PDF](prl2021/papers/PRL2021_paper_37.pdf))
* Domain-independent reward machines for modular integration of planning and learning ([PDF](prl2021/papers/PRL2021_paper_38.pdf))
* Learning a Symbolic Planning Domain through the Interaction with Continuous Environments ([PDF](prl2021/papers/PRL2021_paper_39.pdf))


## Submission Instructions

We solicit workshop paper submissions relevant to the above call of the following types:
- Long papers — up to 8 pages + unlimited references/appendices
- Short papers — up to 4 pages + unlimited references/appendices
- Extended abstracts — up to 2 pages + unlimited references/appendices

Please format submissions in AAAI style (see instructions in the [Author Kit 2021 at AAAI, http://www.aaai.org/Publications/Templates/AuthorKit21.zip](http://www.aaai.org/Publications/Templates/AuthorKit21.zip)).

Some accepted long papers will be accepted as contributed talks. All accepted long and short papers and extended abstracts will be given a slot in the poster presentation session. Extended abstracts are intended as brief summaries of already published papers (a reference to the publication is expected), preliminary work, position papers or challenges that might help bridge the gap.

Paper submissions should be made through [EasyChair, https://easychair.org/conferences/?conf=prl2021](https://easychair.org/conferences/?conf=prl2021).

Please send your inquiries by email to the organizers at [prl.theworkshop@gmail.com](mailto:prl.theworkshop@gmail.com).

For up-to-date information, please visit the [PRL website, https://prl-theworkshop.github.io](https://prl-theworkshop.github.io).


## Important Dates

- Submission deadline: April 21, 2021 (PASSED)
- Notification date: May 14, 2021. (PASSED)
- Camera-ready deadline: June 25, 2021. ––extended two weeks. Upload it through [EasyChair](https://easychair.org/conferences/?conf=prl2021). (PASSED)
- Workshop date: August 4-6, 2021

The reference timezone for all deadlines is UTC-12.

## Previous Edition

[PRL @ ICAPS 2020](https://prl-theworkshop.github.io/icaps20subpages.icaps-conference.org/workshops/prl/)

## Organizers

- [Hector Palacios](http://hectorpalacios.net/)
- [Vicenç Gómez](https://www.upf.edu/web/vgomez)
- [Anders Jonsson](https://www.upf.edu/web/anders-jonsson)
- [Alan Fern](http://web.engr.oregonstate.edu/~afern/)
- [Andrey Kolobov](https://www.microsoft.com/en-us/research/people/akolobov/)
- [Scott Sanner](http://d3m.mie.utoronto.ca)
