# Bridging the Gap Between AI Planning and Reinforcement Learning (PRL) – [Workshop at ICAPS 2021 (August 5-6)](https://icaps21.icaps-conference.org/workshops/PRL/)

### This site presents the most up-to-date information about the workshop. Please, visit [ICAPS 2021](https://icaps21.icaps-conference.org/) for more general information.

While AI Planning and Reinforcement Learning communities focus on similar sequential decision-making problems, these communities remain somewhat unaware of each other on specific problems, techniques, methodologies, and evaluation.

This workshop aims to encourage discussion and collaboration between the researchers in the fields of AI planning and reinforcement learning. We aim to bridge the gap between the two communities, facilitate the discussion of differences and similarities in existing techniques, and encourage collaboration across the fields. We solicit interest from AI researchers that work in the intersection of planning and reinforcement learning, in particular, those that focus on intelligent decision making. As such, the joint workshop program is an excellent opportunity to gather a large and diverse group of interested researchers.

## Topics

The workshop solicits work at the intersection of the fields of reinforcement learning and planning. We also solicit work solely in one area that can influence advances in the other so long as the connections are clearly articulated in the submission.

Submissions are invited for topics on, but not limited to:

- Reinforcement learning (model-based, Bayesian, deep, etc.)
- Model representation and learning for planning
- Planning using approximated/uncertain (learned) models
- Monte Carlo planning
- Learning search heuristics for planner guidance
- Theoretical aspects of planning and reinforcement learning
- Reinforcement Learning and planning competition(s)
- Multi-agent planning and learning
- Applications of both reinforcement learning and planning

## Invited Speakers

- [Aviv Tamar](https://avivt.github.io/avivt/) – "Learning to Plan and Planning to Learn"
- [Danijar Hafner](https://danijar.com) - "General Agents through World Models"
- [Emma Brunskill](https://cs.stanford.edu/people/ebrun/) – "Careful Pessimism"
   - Abstract: There is significant potential to better leverage historical data to improve future decision making, as in offline batch reinforcement learning. Pessimism with respect to quantified uncertainty has received significant recent interest in offline batch RL methods. I’ll present some of our recent work in this direction including pessimistic Bellman backup planning.
- [André Barreto](https://www.lncc.br/~amsb/) – "Value-Based Representation and Model Learning"
- [Elias Bareinboim](https://causalai.net)

## Program outline

The event will be fully virtual, consisting of:

* Invited talks. 30m + 10m for Q&A.
* Oral presentations for some papers. 8m + 2m for Q&A.
* One poster session. 60m.
* Discussion sessions. 20m.

The **confirmed** time slots for the PRL workshops are:

* August 5th and 6th
* Both days from 14h-19h GMT. That is
	* 16h-21h CET, Central European Time.
	* 10h-15h EST, US East time.

These slots accommodate the time zone of 18 the 25 accepted papers.

## Program details – DRAFT

NB: The order of the _contributed_ talks is likely to change.

### Thursday, August 5 (14h-19h GMT)

| Time (EST) | | 
| ------------- | ------------- |
| 10:00  | Invited Talk: Danijar Hafner. <em>General Agents through World Models</em> |
| 10:40  | Contributed talk: AI Planning Annotation in Reinforcement Learning: Options and Beyond  |
| 10:50  | Contributed talk: Efficient PAC Reinforcement Learning in Regular Decision Processes |
| 11:00  | Break |
| 11:15  | Invited Talk:  |
| 11:55  |	Discussion Session  |
| 12:15  |	Posters  |
| 13:15  |	Break  |
| 13:30  |	Invited Talk: Emma Brunskill. <em>Careful Pessimism</em>|
| 14:10  |	Contributed talk: Extending Graph Neural Networks for Generalized Stochastic Planning |
| 14:20  |	Contributed talk: Online Learning of Generalised Linear Function Approximation in Relational MDPs |
| 14:30  |	Contributed talk: RePReL : Integrating Relational Planning and Reinforcement Learning for Effective Abstraction|
| 14:40  |	Discussion Session  |

### Friday, August 6 (14h-19h GMT)

| Time (EST) | | 
| ------------- | ------------- |
| 10:00 | Invited Talk |
| 10:40 | Contributed talk: Reinforcement Learning for Classical Planning: Viewing Heuristics as Dense Reward Generators |
| 10:50 | Contributed talk: Domain-independent reward machines for modular integration of planning and learning |
| 11:00 | Contributed talk: Neural Network Heuristic Functions for Classical Planning: Reinforcement Learning and Comparison to Other Methods |
| 11:10 | Discussion Session |
| 11:30 | Break |
| 11:45 | Invited Talk: Elias Bareinboim |
| 12:25 | Contributed talk: Neural Network Action Policy Verification via Predicate Abstraction |
| 12:35 | Contributed talk: Debugging a Policy: A Framework for Automatic Action Policy Testing|
| 12:45 | Contributed talk: AlwaysSafe: Reinforcement Learning without Safety Constraint Violations during Training (Extended Abstract)|
| 12:55 | Discussion Session and closing remarks |

## Accepted papers – poster #

(Authors: The numbers below will be used for indicating the spot during the poster session. They are different from the Easychair ID). 

* #1: Efficient PAC Reinforcement Learning in Regular Decision Processes (Alessandro Ronca and Giuseppe De Giacomo) ([PDF](prl2021/papers/PRL2021_paper_37.pdf))
* #2: Predictive Control Using Learned State Space Models via Rolling Horizon Evolution (Alvaro Ovalle and Simon Lucas) ([PDF](prl2021/papers/PRL2021_paper_17.pdf))
* #3: Discount Factor Estimation in a Model-Based Inverse Reinforcement Learning Framework (Babatunde Giwa and Chi-Guhn Lee) ([PDF](prl2021/papers/PRL2021_paper_21.pdf))
* #4: Learning Search Guidance from Failures with Eliminable Edge Sets (Catherine Zeng and Tom Silver) ([PDF](prl2021/papers/PRL2021_paper_10.pdf))
* #5: Reinforcement Learning for Classical Planning: Viewing Heuristics as Dense Reward Generators (Clement Gehring, Masataro Asai, Rohan Chitnis, Tom Silver, Leslie Kaelbling, Shirin Sohrabi and Michael Katz) ([PDF](prl2021/papers/PRL2021_paper_26.pdf))
* #6: Open-Loop Online Planning for F1 Race Strategy Identification (Diego Piccinotti, Amarildo Likmeta, Nicolo Brunello and Marcello Restelli) ([PDF](prl2021/papers/PRL2021_paper_1.pdf))
* #7: dcss ai wrapper: An API for Dungeon Crawl Stone Soup providing both Vector and Symbolic State Representations (Dustin Dannenhauer, Zohreh A. Dannenhauer, Jonathon Decker, Adam Amos-Binks, Michael Floyd and David Aha) ([PDF](prl2021/papers/PRL2021_paper_24.pdf))
* #8: Learning a Symbolic Planning Domain through the Interaction with Continuous Environments (Elena Umili, Emanuele Antonioni, Francesco Riccio, Roberto Capobianco, Daniele Nardi and Giuseppe De Giacomo) ([PDF](prl2021/papers/PRL2021_paper_39.pdf))
* #9: Obtaining Approximately Admissible Heuristic Functions through Deep Reinforcement Learning and A* Search (Forest Agostinelli, Stephen McAleer, Alexander Shmakov, Roy Fox, Marco Valtorta, Biplav Srivastava and Pierre Baldi) ([PDF](prl2021/papers/PRL2021_paper_23.pdf))
* #10: Domain-independent reward machines for modular integration of planning and learning (Giuseppe De Giacomo, Marco Favorito, Luca Iocchi and Fabio Patrizi) ([PDF](prl2021/papers/PRL2021_paper_38.pdf))
* #11: RePReL : Integrating Relational Planning and Reinforcement Learning for Effective Abstraction (Harsha Kokel, Arjun Manoharan, Sriraam Natarajan, Balaraman Ravindran and Prasad Tadepalli) ([PDF](prl2021/papers/PRL2021_paper_5.pdf))
* #12: SOLO: Search Online, Learn Offline for Combinatorial Optimization Problems (Joel Oren, Chana Ross, Maksym Lefarov, Felix Richter, Ayal Taitler, Zohar Feldman Zohar Feldman, Dotan Di Castro and Christian Daniel) ([PDF](prl2021/papers/PRL2021_paper_4.pdf))
* #13: First-Order Function Approximation for Transfer Learning in Relational MDPs (Jun Hao Alvin Ng and Ron Petrick) ([PDF](prl2021/papers/PRL2021_paper_11.pdf))
* #14: AI Planning Annotation in Reinforcement Learning: Options and Beyond (Junkyu Lee, Michael Katz, Don Joven Agravante, Miao Liu, Tim Klinger, Murray Campbell, Shirin Sohrabi and Gerald Tesauro) ([PDF](prl2021/papers/PRL2021_paper_36.pdf))
* #15: Debugging a Policy: A Framework for Automatic Action Policy Testing (Marcel Steinmetz, Timo P. Gros, Philippe Heim, Daniel Höller and Joerg Hoffmann) ([PDF](prl2021/papers/PRL2021_paper_16.pdf))
* #16: Neural Network Action Policy Verification via Predicate Abstraction (Marcel Vinzent and Jörg Hoffmann) ([PDF](prl2021/papers/PRL2021_paper_7.pdf))
* #17: Bounded-Suboptimal Search with Learned Heuristics (Matias Greco and Jorge A. Baier) ([PDF](prl2021/papers/PRL2021_paper_33.pdf))
* #18: Scalable Risk-Sensitive Planning by Gradient Descent (Noah Patton, Jihwan Jeong, Michael Gimelfarb and Scott Sanner) ([PDF](prl2021/papers/PRL2021_paper_30.pdf))
* #19: Neural Network Heuristics for Classical Planning: Reinforcement Learning and Comparison to Other Methods (Patrick Ferber, Florian Geißer, Felipe Trevizan, Malte Helmert and Joerg Hoffmann) ([PDF](prl2021/papers/PRL2021_paper_20.pdf))
* #20: Can Reinforcement Learning solve the Human Allocation Problem? (Phong Nguyen) ([PDF](prl2021/papers/PRL2021_paper_15.pdf))
* #21: A Reinforcement Learning Environment For Job-Shop Scheduling (Pierre Tassel, Martin Gebser and Konstantin Schekotihin) ([PDF](prl2021/papers/PRL2021_paper_9.pdf))
* #22: AlwaysSafe: Reinforcement Learning without Safety Constraint Violations during Training (Extended Abstract) (Thiago D. Simão, Nils Jansen and Matthijs T. J. Spaan) ([PDF](prl2021/papers/PRL2021_paper_13.pdf))
* #23: A Generic Dialog Agent for Information Retrieval Based on Automated Planning Within a Reinforcement Learning Platform (Vishal Pallagani and Biplav Srivastava) ([PDF](prl2021/papers/PRL2021_paper_28.pdf))
* #24: Guiding Robot Exploration in Reinforcement Learning via Automated Planning: an Abstract (Yohei Hayamizu, Saeid Amiri, Kishan Chandan, Keiki Takadama and Shiqi Zhang) ([PDF](prl2021/papers/PRL2021_paper_35.pdf))
* #25: Extending Graph Neural Networks for Generalized Stochastic Planning (Ziqi Zhang and Florian Geißer) ([PDF](prl2021/papers/PRL2021_paper_31.pdf))

## Submission Instructions

We solicit workshop paper submissions relevant to the above call of the following types:
- Long papers — up to 8 pages + unlimited references/appendices
- Short papers — up to 4 pages + unlimited references/appendices
- Extended abstracts — up to 2 pages + unlimited references/appendices

Please format submissions in AAAI style (see instructions in the [Author Kit 2021 at AAAI, http://www.aaai.org/Publications/Templates/AuthorKit21.zip](http://www.aaai.org/Publications/Templates/AuthorKit21.zip)).

Some accepted long papers will be accepted as contributed talks. All accepted long and short papers and extended abstracts will be given a slot in the poster presentation session. Extended abstracts are intended as brief summaries of already published papers (a reference to the publication is expected), preliminary work, position papers or challenges that might help bridge the gap.

Paper submissions should be made through [EasyChair, https://easychair.org/conferences/?conf=prl2021](https://easychair.org/conferences/?conf=prl2021).

Please send your inquiries by email to the organizers at [prl.theworkshop@gmail.com](mailto:prl.theworkshop@gmail.com).

For up-to-date information, please visit the [PRL website, https://prl-theworkshop.github.io](https://prl-theworkshop.github.io).


## Important Dates

- Submission deadline: April 21, 2021 (PASSED)
- Notification date: May 14, 2021. (PASSED)
- Camera-ready deadline: June 25, 2021. ––extended two weeks. Upload it through [EasyChair](https://easychair.org/conferences/?conf=prl2021). (PASSED)
- Workshop date: August 4-6, 2021

The reference timezone for all deadlines is UTC-12.

## Previous Edition

[PRL @ ICAPS 2020](https://prl-theworkshop.github.io/icaps20subpages.icaps-conference.org/workshops/prl/)

## Organizers

- [Alan Fern](http://web.engr.oregonstate.edu/~afern/)
- [Vicenç Gómez](https://www.upf.edu/web/vgomez)
- [Anders Jonsson](https://www.upf.edu/web/anders-jonsson)
- [Andrey Kolobov](https://www.microsoft.com/en-us/research/people/akolobov/)
- [Hector Palacios](http://hectorpalacios.net/) – chair
- [Scott Sanner](http://d3m.mie.utoronto.ca)
